aws:
  access_key_id: AKIAIN7K6FAZS7ZYVLSA
  secret_access_key: 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
  s3:
    region: us-west-1
    buckets:
      assets: s3://snowplow-hosted-assets # DO NOT CHANGE unless you are hosting the jarfiles etc yourself in your own bucket
      jsonpath_assets: 
      log: s3://elasticbeanstalk-us-west-1-064536403946/resources/logs
      raw:
        in:
          - s3://elasticbeanstalk-us-west-1-064536403946/resources/logs
        processing: s3://elasticbeanstalk-us-west-1-064536403946
        archive: s3://elasticbeanstalk-us-west-1-064536403946/resources/logs
      enriched:
        good: s3://elasticbeanstalk-us-west-1-064536403946/resources/logs
        bad: s3://elasticbeanstalk-us-west-1-064536403946/resources/logs
        errors: s3://elasticbeanstalk-us-west-1-064536403946/resources/logs
        archive: s3://elasticbeanstalk-us-west-1-064536403946/resources/logs
      shredded:
        good: s3://elasticbeanstalk-us-west-1-064536403946/resources/logs
        bad: s3://elasticbeanstalk-us-west-1-064536403946/resources/logs
        errors: s3://elasticbeanstalk-us-west-1-064536403946/resources/logs
        archive: s3://elasticbeanstalk-us-west-1-064536403946/resources/logs
  emr:
    ami_version: 5.9.0
    region: us-west-1
    jobflow_role: EMR_EC2_DefaultRole
    service_role: EMR_DefaultRole
    placement:
    ec2_subnet_id: subnet-46a42c1e
    ec2_key_name: snowplow-ec2
    bootstrap: []
    software:
      hbase:
      lingual:
    # Adjust your Hadoop cluster below
    jobflow:
      job_name: My cluster 2
      master_instance_type: m3.xlarge
      core_instance_count: 1
      core_instance_type: m3.xlarge
      core_instance_ebs:    
        volume_size: 80
        volume_type: "gp2"
        volume_iops: 400
        ebs_optimized: false
      task_instance_count: 1
      task_instance_type: m3.xlarge
      task_instance_bid: 0.015
    bootstrap_failure_tries: 3
    configuration:
      yarn-site:
        yarn.resourcemanager.am.max-attempts: "1"
      spark:
        maximizeResourceAllocation: "true"
    additional_info:
collectors:
  format: 'clj-tomcat'
enrich:
  versions:
    spark_enrich: 1.14.0
  continue_on_unexpected_error:
  output_compression: NONE
storage:
  versions:
    rdb_loader: 0.14.0
    rdb_shredder: 0.13.0
    hadoop_elasticsearch: 0.1.0
monitoring:
  tags: {test}
  logging:
    level: DEBUG # You can optionally switch to INFO for production
  snowplow:
    method: get
    app_id: snowplow # e.g. snowplow
    collector: SnowplowCollectorDemo-env.us-west-1.elasticbeanstalk.com
